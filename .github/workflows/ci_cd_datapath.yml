name: CI/CD Airflow DAGs

on:
  push:
    branches:
      - main  # Ejecuta el pipeline solo en la rama main

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repo content
      uses: actions/checkout@v2

    #Verificar si hubo cambios en la carpeta "dags/"
    - name: Check for DAG changes
      id: check_dags
      uses: dorny/paths-filter@v2
      with:
        filters: |
          dags:
            - 'dags/**'

    #Validar DAGs antes del despliegue
    - name: Validate DAGs
      if: steps.check_dags.outputs.dags == 'true'  # Solo ejecuta si hay cambios en "dags/"
      run: |
        pip install apache-airflow
        airflow dags list

    - name: Set up Python
      if: steps.check_dags.outputs.dags == 'true'
      uses: actions/setup-python@v2
      with:
        python-version: '3.8'

    - name: Install SSH key
      if: steps.check_dags.outputs.dags == 'true'
      uses: shimataro/ssh-key-action@v2
      with:
        key: ${{ secrets.SSH_PRIVATE_KEY }}
        known_hosts: ${{ secrets.SSH_KNOWN_HOSTS }}

    # Desplegar los DAGs solo si hubo cambios en la carpeta "dags/"
    - name: Copy DAG files to Airflow server
      if: steps.check_dags.outputs.dags == 'true'
      run: |
        scp -r ./dags/* your_user@your_airflow_server:/path/to/airflow/dags

    #Reiniciar Airflow solo si hubo cambios
    - name: Restart Airflow
      if: steps.check_dags.outputs.dags == 'true'
      run: |
        ssh your_user@your_airflow_server 'sudo systemctl restart airflow-scheduler airflow-webserver'
